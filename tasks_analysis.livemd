# Tasks analysis

```elixir
Mix.install([
  {:merquery, "~> 0.3.0"},
  {:req, "~> 0.5.16"},
  {:kino, "~> 0.18.0"},
  {:vega_lite, "~> 0.1.11"},
  {:kino_vega_lite, "~> 0.1.13"},
  {:jason, "~> 1.4"},
])
```

## Введение

Для разработки программного средства для аналитики задач был выбран язык Elixir и проект Livebook.

Для визуализации используется библиотека VegaLite

```elixir
alias VegaLite, as: Vl
```

```elixir
IO.puts "Hello, World"
```

Для выполнения HTTP запросов в проект добавлены библиотеки

* [req](https://hexdocs.pm/req/readme.html) http client
* [merquery](https://github.com/acalejos/merquery) smart-cell обёртка над req

```elixir
{:ok, %{status: st}} = Req.get("https://api.github.com/repos/elixir-lang/elixir")
st
```

## 0. Общие для всех запросов параметры

```elixir
jira_url = "https://issues.apache.org/jira/rest/api/2"
kafka = "KAFKA"
headers = [{"Accept", "application/json"}]

test_url = "#{jira_url}/project/#{kafka}"
```

## 1. Время, которое задача провела от момента создания до момента закрытия

Построение гистограммы, отражающей время, которое задача провела в
открытом состоянии (от момента создания до момента закрытия). По оси
абсцисс – расположить время. По оси ординат – расположить суммарное
количество задач, которое было в открытом виде соответствующее время. В
расчет брать только закрытые задачи по проекту;

```elixir
defmodule JiraFetcher do
  def fetch_page(base_url, headers, jql, start_at, fields, expand \\ nil) do
    url = "#{base_url}/search"
    params = [
      jql: jql,
      startAt: start_at,
      maxResults: 100,
      fields: fields,
    ]
    params =
      if expand do
        Keyword.put(params, :expand, expand)
      else
        params
      end
    
    case Req.get(url, headers: headers, params: params) do
      {:ok, %{status: 200, body: body}} -> {:ok, body}
      {:ok, response} ->
        IO.inspect(response, label: "Ошибка запроса")
        {:error, response}
    end
  end

  def fetch_all_closed_issues_with_history(base_url, headers, project_key) do
    jql = "project = #{project_key} AND status = Closed"

    Stream.resource(
      fn -> 0 end,
      fn start_at ->
        case fetch_page(base_url, headers, jql, start_at, "created,status,updated,resolutiondate", "changelog") do
          {:ok, %{"issues" => issues, "total" => total}} ->
            if issues == [] or start_at >= total do
              {:halt, start_at}
            else
              {issues, start_at + length(issues)}
            end
          _ -> {:halt, start_at}
        end
      end,
      fn _ -> :ok end
    )
    |> Enum.to_list()
  end

  def fetch_all_issues(base_url, headers, project_key) do
    jql = "project = #{project_key}"

    Stream.resource(
      fn -> 0 end,
      fn start_at ->
        case fetch_page(base_url, headers, jql, start_at, "created,status,updated,resolutiondate", "changelog") do
          {:ok, %{"issues" => issues, "total" => total}} ->
            if issues == [] or start_at >= total do
              {:halt, start_at}
            else
              {issues, start_at + length(issues)}
            end
          _ -> {:halt, start_at}
        end
      end,
      fn _ -> :ok end
    )
    |> Enum.to_list()
  end

  def fetch_all_issues_with_users(base_url, headers, project_key) do
    jql = "project = #{project_key}"
    
    Stream.resource(
      fn -> 0 end,
      fn start_at ->
        # Запрашиваем поля assignee (исполнитель) и reporter (репортер)
        case fetch_page(base_url, headers, jql, start_at, "assignee,reporter") do
          {:ok, %{"issues" => issues, "total" => total}} ->
            if issues == [] or start_at >= total do
              {:halt, start_at}
            else
              {issues, start_at + length(issues)}
            end
          _ -> {:halt, start_at}
        end
      end,
      fn _ -> :ok end
    )
    |> Enum.to_list()
  end
end

```

```elixir
all_closed_issues = JiraFetcher.fetch_all_closed_issues_with_history(jira_url, headers, kafka)
```

```elixir
all_closed_issues
|> length()

issue = Enum.at(all_closed_issues, 10)

# Map of `Livespan => Number of issues with that timespan`
frequencies =
  all_closed_issues
  |> Enum.reduce([], fn issue, acc ->
      closed_at_record = issue["changelog"]["histories"]
      |> Enum.flat_map(fn entry ->
        entry["items"]
        |> Enum.filter(fn item ->
          item["fromString"] && item["toString"] && item["field"] == "status"
        end)
        |> Enum.map(fn item ->
            %{
              "created" => entry["created"],
              "fromString" => item["fromString"],
              "toString" => item["toString"]
            }
        end)
      end)
      |> Enum.reverse()
      |> Enum.find(fn entry ->
        entry["toString"] == "Closed"   
      end)
      case closed_at_record do
        %{"created"=> closed_at_str} ->
          {:ok, created_at, _} = DateTime.from_iso8601(issue["fields"]["created"])
          {:ok, closed_at, _} = DateTime.from_iso8601(closed_at_str)
          time_to_close = DateTime.diff(closed_at, created_at, :day)
          [time_to_close | acc ]
          _ -> acc
      end
    end)
  |> Enum.frequencies()

{min_livespan, max_livespan} = Map.keys(frequencies) |> Enum.min_max()
x_data = min_livespan..max_livespan

y_data =
  Enum.reduce(x_data, [], fn livespan, acc ->
    [Map.get(frequencies, livespan, 0) | acc]
  end)
  |> Enum.reverse()

first_chart_data = %{
  x_data: x_data,
  y_data: y_data
}
```

```elixir
clip_after = 100

Vl.new(width: 700, height: 500, title: "Распределение времени жизни задач в открытом состоянии")
|> Vl.data_from_values(first_chart_data, only: ["x_data", "y_data"])
|> Vl.mark(:bar)
# |> Vl.transform(filter: "datum.x_data <= #{clip_after}")
# |> Vl.encode_field(:x, "x_data", type: :quantitative, title: "Время", scale: [domain_min: 0, domain_max: clip_after, zero: true])
|> Vl.encode_field(:x, "x_data", type: :quantitative, title: "Время в открытом состоянии (дни)", scale: [type: :pow, exponent: 0.5, domain_min: 0, zero: true])
|> Vl.encode_field(:y, "y_data", type: :quantitative, title: "Частота встречаемости")

```

## 2. Распределение времени жизни задач в определённом статусе

построить диаграммы, которые показывают распределение времени по состояниям задачи. По оси абсцисс – расположить время. По оси ординат – расположить суммарное количество задач, которое было в открытом виде соответствующее время. В расчет брать только закрытые задачи по проекту.
Для каждого состояния должна строиться своя диаграмма

```elixir
issues_with_history = JiraFetcher.fetch_all_closed_issues_with_history(jira_url, headers, kafka)
```

```elixir
defmodule IssueParser do
  def get_datetime!(issue, field_type) do
    {:ok, datetime, _} = DateTime.from_iso8601(issue["fields"][field_type])
    datetime
  end
end

defmodule StatusTimeCalculator do
  def total_time_in_status(data, "Open") do
    opened_at = data["created"]
    changed_from_open =
      data["changes"]
      |> Enum.find(fn entry ->
        entry["fromString"] == "Open"   
      end)
      |> get_in(["created"])
    
    DateTime.diff(changed_from_open, opened_at, :second)
  end
  
  def total_time_in_status(data, target_status) do
    # Извлекаем массив переходов из ключа "changes"
    transitions = Map.get(data, "changes", [])
    
    transitions
    |> Enum.sort_by(& &1["created"], DateTime)
    |> find_time_spans(target_status)
    |> Enum.reduce(0, fn {start_time, end_time}, acc ->
      DateTime.diff(end_time, start_time, :second) + acc
    end)
  end

  defp find_time_spans(sorted_transitions, target_status) do
    {_, spans} = 
      Enum.reduce(sorted_transitions, {nil, []}, fn 
        transition, {current_status, acc} ->
          # Если входим в целевой статус
          if transition["toString"] == target_status do
            {target_status, [{transition["created"], nil} | acc]}
          
          # Если выходим из целевого статуса
          else if transition["fromString"] == target_status do
            # Обновляем последний промежуток с конечным временем
            updated_acc = update_last_span(acc, transition["created"])
            {nil, updated_acc}
          
          else
            {current_status, acc}
          end
        end
      end)
    
    # Фильтруем только завершенные промежутки
    Enum.filter(spans, fn
      {_start, nil} -> false
      {_, _} -> true
    end)
  end

  defp update_last_span([], _end_time), do: []
  defp update_last_span([{start, nil} | rest], end_time) do
    [{start, end_time} | rest]
  end
  defp update_last_span([span | rest], end_time) do
    [span | update_last_span(rest, end_time)]
  end
end
```

```elixir
IO.puts(Enum.count(issues_with_history))

# Проверка на то, что во всех подтянутых задачах подтянулась вся история изменений.
# Ответ: Да, во всех закрытых подтягивается полностью
# Enum.each(issues_with_history, fn issue ->
#   total = issue["changelog"]["total"]
#   loaded_total = issue["changelog"]["histories"] |> Enum.count()
#   if total != loaded_total do
#     false
#   end
# end)

defmodule ViewStatusTimeDistribution do
  def has_status(issue, status) do
    with %{"changelog" => %{"histories" => histories}} <- issue do
      Enum.any?(histories, fn history ->
        items = history["items"]
        Enum.any?(items, fn item ->
          if item["field"] == "status" do
            item["toString"] == status
          else
            false
          end
        end)
      end)
    else
      _ -> false
    end
  end

  def get_status_time_distribution(issues_with_history, status) do
    issues_with_desired_status =
      Enum.filter(issues_with_history, fn issue -> has_status(issue, status) end)
    
    frequencies =
      issues_with_desired_status
      |> Enum.reduce([], fn issue, acc ->
        status_changes =
          issue["changelog"]["histories"]
          |> Enum.filter(fn history ->
            Enum.any?(history["items"], fn item ->
              if item["field"] == "status" do
                true
              else
                false
              end
            end)
          end)
          |> Enum.flat_map(fn entry ->
            entry["items"]
            |> Enum.filter(fn item ->
              item["fromString"] && item["toString"] && item["field"] == "status"
            end)
            |> Enum.map(fn item ->
              %{
                "created" => entry["created"],
                "fromString" => item["fromString"],
                "toString" => item["toString"]
              }
            end)
          end)
          |> Enum.map(fn change ->
            {:ok, from, _} = DateTime.from_iso8601(change["created"])
            %{change | "created" => from}
          end)
        
        issue_history = %{
          "created" => IssueParser.get_datetime!(issue, "created"),
          "changes" => status_changes
        }
        seconds_in_status = StatusTimeCalculator.total_time_in_status(issue_history, status)
        [trunc(seconds_in_status / 86400) | acc]
      end)
      |> Enum.frequencies()
    
    {min_livespan, max_livespan} = Map.keys(frequencies) |> Enum.min_max()
    x_data = min_livespan..max_livespan
    
    y_data =
      Enum.reduce(x_data, [], fn livespan, acc ->
        [Map.get(frequencies, livespan, 0) | acc]
      end)
      |> Enum.reverse()
    
    second_chart_data = %{
      x_data: x_data,
      y_data: y_data
    }
    view(second_chart_data, status)
  end
  
  def view(chart_data, status) do
    clip_after = 100

    Vl.new(width: 700, height: 500, title: "Распределение времени жизни задач в статусе #{status}")
    |> Vl.data_from_values(chart_data, only: ["x_data", "y_data"])
    |> Vl.mark(:bar)
    # |> Vl.transform(filter: "datum.x_data <= #{clip_after}")
    # |> Vl.encode_field(:x, "x_data", type: :quantitative, title: "Время в состоянии (дни)", scale: [domain_min: 0, domain_max: clip_after, zero: true])
      |> Vl.encode_field(:x, "x_data", 
          type: :quantitative, title: "Время в состоянии (дни)",
          scale: [type: :pow, exponent: 0.5, domain_min: 0, zero: true]
      )
    |> Vl.encode_field(:y, "y_data", type: :quantitative, title: "Частота встречаемости")

  end
end
```

```elixir
statuses = [
  "Open",
  "In Progress",
  "Reopened",
  "Resolved",
  "Closed",
  "Patch Available"
]
ViewStatusTimeDistribution.get_status_time_distribution(issues_with_history, "Open")
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
ViewStatusTimeDistribution.get_status_time_distribution(issues_with_history, "In Progress")
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
ViewStatusTimeDistribution.get_status_time_distribution(issues_with_history, "Reopened")
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
ViewStatusTimeDistribution.get_status_time_distribution(issues_with_history, "Resolved")
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir

ViewStatusTimeDistribution.get_status_time_distribution(issues_with_history, "Closed")
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
ViewStatusTimeDistribution.get_status_time_distribution(issues_with_history, "Patch Available")
```

## 3. Количество открытых и закрытых задач по дням и накопительный итог

построить график, показывающий количество заведенных и закрытых задач в день. График должен отражать не только информацию о количестве задач в день, но и накопительный итог по задачам. По оси абсцисс – расположить календарные дни. По оси ординат – расположить суммарное количество задач для этого дня (открытые, закрытые и для каждого – накопительный итог);

<!-- livebook:{"break_markdown":true} -->

**Клетка ниже будет загружать данные около 200 секунд, так что просто так её не запускайте**

```elixir
all_issues = JiraFetcher.fetch_all_issues(jira_url, headers, kafka)
```

```elixir
Enum.count(all_issues) # 18723. Yes we got them all

defmodule DailyTaskStats do
  def calculate_daily_stats(issues) do
    # Парсим даты создания и закрытия
    issues
    |> Enum.map(fn issue ->
      {:ok, created_dt, _} = DateTime.from_iso8601(issue["fields"]["created"])
      created_date = Date.to_iso8601(Date.from_erl!({created_dt.year, created_dt.month, created_dt.day}))
      
      closed_date = case issue["fields"]["resolutiondate"] do
        nil -> nil
        date_str -> 
          {:ok, closed_dt, _} = DateTime.from_iso8601(date_str)
          Date.to_iso8601(Date.from_erl!({closed_dt.year, closed_dt.month, closed_dt.day}))
      end
      
      %{created: created_date, closed: closed_date}
    end)
  end

   def aggregate_daily_data(stats) do
    # Инициализируем пустую мапу для агрегации
    # %{
    #   date: "2011-08-10",
    #   created_daily: 1,
    #   closed_daily: 2,
    #   created_cumulative: 93,
    #   closed_cumulative: 56
    # }
    daily_data = %{}
    
    # Агрегируем по дням
    daily_data = Enum.reduce(stats, daily_data, fn stat, acc ->
      # Увеличиваем счетчик созданных задач
      created_count = Map.get(acc, stat.created, %{created: 0, closed: 0})
      created_count = %{created_count | created: created_count.created + 1}
      acc = Map.put(acc, stat.created, created_count)
      
      # Если задача закрыта, увеличиваем счетчик закрытых
      if stat.closed do
        closed_count = Map.get(acc, stat.closed, %{created: 0, closed: 0})
        closed_count = %{closed_count | closed: closed_count.closed + 1}
        Map.put(acc, stat.closed, closed_count)
      else
        acc
      end
    end)
    
    # Сортируем даты по возрастанию
    sorted_dates = Map.keys(daily_data) |> Enum.sort()
    
    # Вычисляем накопительные итоги
    cumulative_data = Enum.reduce(
        sorted_dates, {[], 0, 0},
        fn date, {acc, cum_created, cum_closed} ->
          day_data = Map.get(daily_data, date)
          new_cum_created = cum_created + day_data.created
          new_cum_closed = cum_closed + day_data.closed
          
          day_record = %{
            date: date,
            created_daily: day_data.created,
            closed_daily: day_data.closed,
            created_cumulative: new_cum_created,
            closed_cumulative: new_cum_closed
          }
          
          {[day_record | acc], new_cum_created, new_cum_closed}
        end
    )
    
    # Возвращаем данные в правильном порядке
    elem(cumulative_data, 0) |> Enum.reverse()
  end

  def create_separate_chart_data(daily_data) do
    # Преобразуем данные в отдельные наборы для каждого типа
    daily_series = 
      Enum.flat_map(daily_data, fn day ->
        [
          %{date: day.date, value: day.created_daily, type: "Создано"},
          %{date: day.date, value: day.closed_daily, type: "Закрыто"}
        ]
      end)
    
    cumulative_series = 
      Enum.flat_map(daily_data, fn day ->
        [
          %{date: day.date, value: day.created_cumulative, type: "Создано"},
          %{date: day.date, value: day.closed_cumulative, type: "Закрыто"}
        ]
      end)
    {daily_series, cumulative_series}
  end
end

stats = DailyTaskStats.calculate_daily_stats(all_issues)
daily_data = DailyTaskStats.aggregate_daily_data(stats)
{daily_series, cumulative_series} = DailyTaskStats.create_separate_chart_data(daily_data)

defmodule DateRangeFilter do
  def filter_by_date_range(list, start_date, end_date) do
    Enum.filter(list, fn %{date: date} ->
      date >= start_date and date <= end_date
    end)
  end
  
  def filter_two_arrays(array1, array2, start_date, end_date) do
    {
      filter_by_date_range(array1, start_date, end_date),
      filter_by_date_range(array2, start_date, end_date)
    }
  end
end

start_date = "2020-12-01"
finish_date = "2025-12-01"
{daily_series, cumulative_series} =
  DateRangeFilter.filter_two_arrays(daily_series, cumulative_series, start_date, finish_date)

```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
Vl.new(width: 600, height: 300, title: ["Количество открытых и закрытых задач по дням и накопительный итог", "с #{start_date} по #{finish_date}"])
|> Vl.data_from_values(daily_series, only: ["date"])
|> Vl.encode_field(:x, "date", type: :temporal, title: "Дни")
|> Vl.layers([
  Vl.new()
  |> Vl.data_from_values(daily_series, only: ["date", "value", "type"])
  |> Vl.mark(:rule)
  |> Vl.encode_field(:y, "value", type: :quantitative, title: "Динамика задач в день")
  |> Vl.encode_field(:color, "type", type: :nominal, title: "Тип задачи"),
  Vl.new()
  |> Vl.data_from_values(cumulative_series, only: ["date", "value", "type"])
  |> Vl.mark(:line)
  |> Vl.encode_field(:y, "value", type: :quantitative, title: "Задач в день накопительно", scale: [domain_min: -2000])
  |> Vl.encode_field(:color, "type", type: :nominal, title: "Тип задачи"),
])
|> Vl.resolve(:scale, y: :independent)
```

## 4. Самые активные пользователи

построить график, выражающий общее количество задач для пользователей, в которых он указан как исполнитель и репортер. По оси абсцисс – расположить количество задач. По оси ординат – расположить имя пользователя. Отразить график для 30 топовых пользователей с максимальным количеством задач;

```elixir
all_issues_with_users = JiraFetcher.fetch_all_issues_with_users(jira_url, headers, kafka)
```

```elixir
defmodule UserTaskStats do
  def calculate_user_stats(issues) do
    # Собираем статистику по пользователям
    Enum.reduce(issues, %{}, fn issue, acc ->
      # Обрабатываем assignee (исполнитель)
      assignee_key = get_user_key(issue["fields"]["assignee"])
      reporter_key = get_user_key(issue["fields"]["reporter"])

      if assignee_key == reporter_key do
        update_user_stats(acc, assignee_key, :both_count)
      else
        acc =
          if assignee_key do
            update_user_stats(acc, assignee_key, :assignee_count)
          else
            acc
          end

        if reporter_key do
          update_user_stats(acc, reporter_key, :reporter_count)
        else
          acc
        end
      end
    end)
  end

  defp get_user_key(user_data) do
    case user_data do
      %{"key" => key, "displayName" => name} -> 
        {key, name}
      %{"key" => key} -> 
        {key, key}
      %{"displayName" => name} -> 
        {name, name}
      _ ->
        nil
    end
  end

  defp update_user_stats(acc, {user_key, user_name}, type) do
    current =
      Map.get(acc, user_key, %{name: user_name, assignee_count: 0, reporter_count: 0, total: 0})

    updated =
      case type do
        :assignee_count ->
          %{current | assignee_count: current.assignee_count + 1}

        :reporter_count ->
          %{current | reporter_count: current.reporter_count + 1}

        :both_count ->
          %{
            current
            | assignee_count: current.assignee_count + 1,
              reporter_count: current.reporter_count + 1
          }
      end

    new_total =
      case type do
        :both_count -> updated.assignee_count + updated.reporter_count - 1
        _ -> updated.assignee_count + updated.reporter_count
      end

    updated = %{updated | total: new_total}

    Map.put(acc, user_key, updated)
  end

  def get_top_users(user_stats, limit \\ 30) do
    user_stats
    |> Map.values()
    |> Enum.sort_by(& &1.total, :desc)
    |> Enum.take(limit)
  end
end

```

```elixir
Enum.random(all_issues_with_users)
Enum.count all_issues_with_users
valid_all_issues_with_users = Enum.filter(all_issues_with_users, fn issue ->
  reporter = issue["fields"]["reporter"]
  assignee = issue["fields"]["assignee"]
  reporter || assignee
end)
user_stats = UserTaskStats.calculate_user_stats(valid_all_issues_with_users)
top_users = UserTaskStats.get_top_users(user_stats)

top_users

```

```elixir
Vl.new()
|> Vl.data_from_values(top_users, only: ["total", "name"])
|> Vl.mark(:bar)
|> Vl.encode_field(:color, "total", type: :quantitative)
|> Vl.encode_field(:x, "total", type: :quantitative)
|> Vl.encode_field(:y, "name", type: :nominal, 
                   sort: [field: "total", order: "descending"])
```

```elixir
top_users
```

```elixir

Vl.new()
|> Vl.data_from_values(top_users)
|> Vl.mark(:bar)
|> Vl.encode_field(:color, "total", type: :quantitative)
|> Vl.encode_field(:x, "total", type: :quantitative)
|> Vl.encode_field(:y, "name", type: :nominal, 
                   sort: [field: "total", order: "descending"])
```

## 5. Время работы пользователя на задачах

построить гистограмму, отражающую время, которое затратил
пользователь на ее выполнение на основе залогированного времени. По оси
абсцисс – расположить время. По оси ординат – расположить суммарное
количество задач, которое соответствует этому времени. В расчет брать только
закрытые задачи по проекту

```elixir
# 5. Гистограмма времени выполнения задач пользователем на основе залогированного времени

defmodule WorklogFetcher do
  def fetch_all_closed_issues_with_worklogs(base_url, headers, project_key) do
    jql = "project = #{project_key} AND statusCategory = Done"

    Stream.resource(
      fn -> 0 end,
      fn start_at ->
        # Запрашиваем worklog для каждой задачи
        case fetch_page(base_url, headers, jql, start_at, "worklog", "") do
          {:ok, %{"issues" => issues, "total" => total}} ->
            if issues == [] or start_at >= total do
              {:halt, start_at}
            else
              {issues, start_at + length(issues)}
            end
          _ -> {:halt, start_at}
        end
      end,
      fn _ -> :ok end
    )
    |> Enum.to_list()
  end

  defp fetch_page(base_url, headers, jql, start_at, fields, expand) do
    url = "#{base_url}/search"
    params = [
      jql: jql,
      startAt: start_at,
      maxResults: 100,
      fields: fields,
      expand: expand
    ]
    
    case Req.get(url, headers: headers, params: params) do
      {:ok, %{status: 200, body: body}} -> {:ok, body}
      {:ok, response} ->
        IO.inspect(response, label: "Ошибка запроса")
        {:error, response}
    end
  end
end
```

```elixir
IO.puts("Загружаем закрытые задачи с worklog...")
issues_with_worklogs = WorklogFetcher.fetch_all_closed_issues_with_worklogs(jira_url, headers, kafka)

IO.puts("Загружено задач: #{Enum.count(issues_with_worklogs)}")
```

```elixir
Enum.random(issues_with_worklogs)
```

```elixir
# Анализируем worklog для каждой задачи
defmodule WorklogAnalyzer do
  def calculate_user_time_per_issue(issues) do
    Enum.flat_map(issues, fn issue ->
      case issue["fields"]["worklog"] do
        %{"worklogs" => worklogs} when is_list(worklogs) ->
          # Группируем время по пользователям для этой задачи
          user_time = 
            worklogs
            |> Enum.group_by(fn worklog -> 
                worklog["author"]["displayName"] || worklog["author"]["name"]
              end)
            |> Enum.map(fn {user, logs} ->
                total_seconds = Enum.reduce(logs, 0, fn log, acc ->
                  acc + (log["timeSpentSeconds"] || 0)
                end)
                %{
                  issue_key: issue["key"],
                  user: user,
                  total_seconds: total_seconds,
                  total_hours: total_seconds / 3600,
                  worklogs_count: length(logs)
                }
              end)
          
          # Если в задаче есть worklog, возвращаем данные
          if user_time != [] do
            user_time
          else
            []
          end
        _ ->
          []
      end
    end)
  end

  def filter_by_min_time(worklog_data, min_seconds \\ 300) do
    Enum.filter(worklog_data, fn item ->
      item[:total_seconds] >= min_seconds
    end)
  end
end

# Получаем данные о времени пользователей
worklog_data = WorklogAnalyzer.calculate_user_time_per_issue(issues_with_worklogs)

IO.puts("Найдено записей worklog: #{Enum.count(worklog_data)}")

# Отфильтруем задачи с очень маленьким временем (меньше 5 минут)
filtered_worklog_data = WorklogAnalyzer.filter_by_min_time(worklog_data, 300)

IO.puts("После фильтрации (≥5 минут): #{Enum.count(filtered_worklog_data)}")

```
